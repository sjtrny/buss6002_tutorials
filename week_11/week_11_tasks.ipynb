{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Newton-Raphson\n",
    "\n",
    "Use Python to find the solution of the following equation\n",
    "$$f(x) = e^x âˆ’ 1 = 0$$\n",
    "using the Newton-Raphson method with random initialisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11514062144393811\n"
     ]
    }
   ],
   "source": [
    "# Here's how you can choose a random starting point\n",
    "import numpy as np\n",
    "\n",
    "x_initial = np.random.randn()\n",
    "\n",
    "print(x_initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 - Newton Raphson\n",
    "\n",
    "Use Newton-Raphson to solve\n",
    "$$\\min_{x} f(x) = x^2 -1$$ \n",
    "\n",
    "with random initialisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 - Newton-Raphson\n",
    "\n",
    "Use Newton-Raphson to solve\n",
    "$$\\min_{x} f(x) = x^5 - 3 x^4 + \\exp(- x^2) \\sin(10 x)$$\n",
    "\n",
    "Remember the number one step of all data science methods: visualise things before you proceed!\n",
    "\n",
    "### Symbolic Differentiation\n",
    "\n",
    "If you need a hand differentiating $f$ then you can try using SymPy, which is a symbolic mathematics library\n",
    "\n",
    "<div style=\"margin-bottom: 0px;\"><img width=20 style=\"display: block; float: left;  margin-right: 20px;\" src=\"img/docs.png\"> <h3 style=\"padding-top: 0px;\">Documentation - SymPy Calculus Tutorial</h3></div>\n",
    "https://docs.sympy.org/latest/tutorial/calculus.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-36*x**2 + 4*x**2*exp(-x**2)*sin(10*x) - 40*x*exp(-x**2)*cos(10*x) - 102*exp(-x**2)*sin(10*x)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sympy import *\n",
    "\n",
    "x = Symbol('x')\n",
    "\n",
    "diff(-12*x**3 - 2*x*exp(-x**2)*sin(10*x) + 5 + 10*exp(-x**2)*cos(10*x), x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Task 4 - Gradient Descent\n",
    "\n",
    "1. Plot the gradient descent path over the objective function for the gradient descent example given in the tutorial\n",
    "2. Given that the true value of beta_1 is 2, have we found discovered the true value exactly? Why or why not?\n",
    "3. What happens if you change alpha to 0.1 or 0.000001?\n",
    "4. What happens if you increase or decrease the number of iterations for a fixed value of alpha?\n",
    "\n",
    "## Task 5 - Stochastic Gradient Descent\n",
    "\n",
    "1. Adapt the code from the tutorial example (and Task 4) to implement SGD\n",
    "\n",
    "You can randomly sample from a list by using https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.choice.html. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2]\n"
     ]
    }
   ],
   "source": [
    "indices = [0, 1, 2, 3, 4]\n",
    "omega = np.random.choice(indices, size = 2)\n",
    "print(omega)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
