{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>BUSS6002 - Data Science in Business</h1></center>\n",
    "\n",
    "#### Pre-Tutorial Checklist\n",
    "\n",
    "1. Complete Task 1 and Task 2 from Week 10\n",
    "\n",
    "# Tutorial 10 - Text Analytics\n",
    "\n",
    "## Text Analytics\n",
    "\n",
    "Often the data that we need to analyse is textual. Text data is incompatible with the models we have discussed so far because the models require numeric values. For example we don't have a direct numeric distance between the words \"hello\" and \"friend\". \n",
    "\n",
    "Moreover sometimes single data points such as a tweet, facebook post etc will contain a large number of words. So we need a way to convert the text data into a flexible numeric representation. This representation should tell us which words occured and how many times.\n",
    "\n",
    "\n",
    "## Bag-of-Words\n",
    "\n",
    "The bag-of-words (BoW) model is a simple method of transforming strings into a numeric representation. BoW treats each word as a feature and the value of the feature is the number of times it occurds.\n",
    "\n",
    "\n",
    "For example the string\n",
    "\n",
    "    \"The quick brown fox jumps over the lazy dog\"\n",
    "    \n",
    "would be transformed into\n",
    "\n",
    "| the | quick | brown | fox | jumps | over | lazy | dog |\n",
    "|---|---|---|---|---|---|---|---|\n",
    "| 2 | 1 | 1 | 1 | 1 | 1 | 1 | 1 |\n",
    "\n",
    "Note that:\n",
    "- the word \"the\" occurs twice so its count is 2\n",
    "- other words are unique so they only occur once\n",
    "- the number of features is the number of unique words\n",
    "\n",
    "To create a BoW set of features\n",
    "\n",
    "<div style=\"margin-bottom: 0px;\"><img width=20 style=\"display: block; float: left;  margin-right: 20px;\" src=\"img/docs.png\"> <h3 style=\"padding-top: 0px;\">Documentation - CountVectorizer</h3></div>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "corpus = [\"The quick brown fox jumps over the lazy dog\",\n",
    "          \"Another dog ran after the fox\"]\n",
    "\n",
    "X = count_vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X is a sparse matrix. To view it we need to convert it to a dense matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1 1 1 1 1 1 1 0 2]\n",
      " [1 1 0 1 1 0 0 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(X.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 10)\t2\n",
      "  (0, 8)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 5)\t1\n",
      "  (0, 7)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 3)\t1\n",
      "  (1, 10)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 0)\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 11)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The matrix isn't that helpful by itself. Lets look at the corresponding feature names (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['after', 'another', 'brown', 'dog', 'fox', 'jumps', 'lazy', 'over', 'quick', 'ran', 'the']\n"
     ]
    }
   ],
   "source": [
    "print(count_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets combine everything into a DataFrame for clarity. You don't always have to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>after</th>\n",
       "      <th>another</th>\n",
       "      <th>brown</th>\n",
       "      <th>dog</th>\n",
       "      <th>fox</th>\n",
       "      <th>jumps</th>\n",
       "      <th>lazy</th>\n",
       "      <th>over</th>\n",
       "      <th>quick</th>\n",
       "      <th>ran</th>\n",
       "      <th>the</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   after  another  brown  dog  fox  jumps  lazy  over  quick  ran  the\n",
       "0      0        0      1    1    1      1     1     1      1    0    2\n",
       "1      1        1      0    1    1      0     0     0      0    1    1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "features = pd.DataFrame(X.todense(), columns = count_vectorizer.get_feature_names())\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## TF-IDF\n",
    "\n",
    "In text data there will be lots of repeated words such as \"a\", \"is\" and \"the\" that aren't very useful. We should ignore them as much as possible.\n",
    "\n",
    "The Term Frequency–Inverse Document Frequency (TF-IDF) is a weighting procedure for BoW data. The TF-IDF weights boost the counts or frequency of uncommon words (which will be useful) and shrinks the mangitude of common words. There are two components to the TF-IDF weights, and each of these can be calculated in different ways:\n",
    "\n",
    "- Term Frequency, often the _raw count_ of a term in a document $tf = f_D$. Other possibilities are boolean (1 if the term appears, otherwise 0), length adjusted ($tf = \\frac{f_D}{n_{words}}$) or logarithmic ($tf = \\log(1+f_D)$).\n",
    "\n",
    "- Inverse Document Frequency, or a measure of the information contained in a word. This is a penalty for commonly used words like 'a' and 'the'. It's the logarithmically scaled inverse fraction of the documents that contain the word (obtained by dividing the total number of documents by the number of documents containing the term, and then taking the logarithm of that quotient). $idf = \\log(\\frac{N}{n_D})$ where $N$ is the number of documents and $n_D$ is the number of documents in which the word appears.\n",
    "\n",
    "The tfidf score is calculated as follows:\n",
    "\n",
    "$$tfidf = tf \\cdot idf $$\n",
    "\n",
    "## TF-IDF in Sklearn\n",
    "\n",
    "Let's vectorise a collection of documents. Notice that each line is treated as a document in this case, so our corpus is a total of 4 documents. \n",
    "\n",
    "<div style=\"margin-bottom: 0px;\"><img width=20 style=\"display: block; float: left;  margin-right: 20px;\" src=\"img/docs.png\"> <h3 style=\"padding-top: 0px;\">Documentation - TfidfVectorizer</h3></div>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"The quick brown fox jumps over the lazy dog\",\n",
    "          \"Another dog ran after the fox\",\n",
    "          \"The world is turning\",\n",
    "          \"Hello world\"\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectoriser = TfidfVectorizer()\n",
    "\n",
    "X = tfidf_vectoriser.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>after</th>\n",
       "      <th>another</th>\n",
       "      <th>brown</th>\n",
       "      <th>dog</th>\n",
       "      <th>fox</th>\n",
       "      <th>hello</th>\n",
       "      <th>is</th>\n",
       "      <th>jumps</th>\n",
       "      <th>lazy</th>\n",
       "      <th>over</th>\n",
       "      <th>quick</th>\n",
       "      <th>ran</th>\n",
       "      <th>the</th>\n",
       "      <th>turning</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.356398</td>\n",
       "      <td>0.280988</td>\n",
       "      <td>0.280988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.356398</td>\n",
       "      <td>0.356398</td>\n",
       "      <td>0.356398</td>\n",
       "      <td>0.356398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454968</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.463709</td>\n",
       "      <td>0.463709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.365594</td>\n",
       "      <td>0.365594</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.463709</td>\n",
       "      <td>0.295980</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.57458</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.366747</td>\n",
       "      <td>0.57458</td>\n",
       "      <td>0.453005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.785288</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.619130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      after   another     brown       dog       fox     hello       is  \\\n",
       "0  0.000000  0.000000  0.356398  0.280988  0.280988  0.000000  0.00000   \n",
       "1  0.463709  0.463709  0.000000  0.365594  0.365594  0.000000  0.00000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.57458   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.785288  0.00000   \n",
       "\n",
       "      jumps      lazy      over     quick       ran       the  turning  \\\n",
       "0  0.356398  0.356398  0.356398  0.356398  0.000000  0.454968  0.00000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.463709  0.295980  0.00000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.366747  0.57458   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000   \n",
       "\n",
       "      world  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.453005  \n",
       "3  0.619130  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.DataFrame(X.todense(), columns = tfidf_vectoriser.get_feature_names())\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin-bottom: 30px;\"><img width=48 style=\"display: block; float: left;  margin-right: 20px;\" src=\"img/question-mark-button.png\"> <h3 style=\"padding-top: 15px;\">Exercise 1 - TF-IDF weights calculation</h3></div>\n",
    "\n",
    "In the corpus with two documents:\n",
    "\n",
    "``On the 24th of February, 1815, the look–out at Notre–Dame de la Garde signalled the three–master, the Pharaon from Smyrna, Trieste, and Naples.``\n",
    "\n",
    "``As usual, a pilot put off immediately, and rounding the Chateau d’If, got on board the vessel between Cape Morgion and Rion island.``\n",
    "\n",
    "Find the TF-IDF weights for the words ``the`` and ``Trieste`` by code or by hand. For term frequency, try Boolean weights."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
